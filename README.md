Object Detection for Visually Impaired People
This project is an AI-powered assistive system that uses object detection and voice feedback to help visually impaired individuals navigate their surroundings independently.

Features:
->Real-time object detection using YOLOv5
->Voice output via text-to-speech (TTS)
->Live webcam input and visual display
->Lightweight and easy to run

Technologies Used:
->Python, OpenCV
->YOLOv5 (Ultralytics)
-.pyttsx3 (for speech synthesis)

Limitations
->Limited object classes
->Repeated voice output without control
->Affected by shaky or low-light video input

Future Enhancements
->Add more object classes
->Support regional language voice
->Integrate depth sensors for proximity alerts
